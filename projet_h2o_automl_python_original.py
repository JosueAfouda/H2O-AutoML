# -*- coding: utf-8 -*-
"""projet_h2o_automl_Python_original.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11SSAjYQchdrlV5hZP9HS7qZ6Z-glfPl8

<h1 align="center">Machine Learning automatique avec H2O AutoML</h1>

*Par [Josué AFOUDA](https://afouda-datascience.com/)*

Pour plus de contenus en Data Science/Machine Learning/deep Learning, veuillez vous abonner à [ma chaîne YouTube](https://www.youtube.com/channel/UCpd56FfjlkKbkHlbgY6XE3w)

Dans ce tutoriel, vous apprendrez ce qu'est **H2O** particulièrement **H2O AutoML** ainsi que son implémentation dans Python à travers un jeu de données réel. En effet, nous construirons de manière automatisée un modèle de machine learning en utilisant les fonctionnalités de H2O AutoML.

## <font color=green> Tâche 1 : Qu'est-ce que H20 AutoML et pourquoi cet outil ?

![h2o_logo.png](attachment:h2o_logo.png)

Avant de vous définir **H20** et surtout **H20 AutoML**, je dois d'abord vous parler de la société **H20.AI**.

**H20.AI** est une entreprise de la Silicon Valley spécialisée dans le développement de logiciels open source en Intelligence Artificielle. Son principal produit est la plateforme **H2O** qui est la principale plateforme open source de Data Science et de Machine Learning utilisée par des centaines de milliers de Data Scientists et d'organisations à travers le monde y compris les 500 plus grandes entreprises du monde.

**H20** est donc un logiciel dont le code de base est écrit en Java mais qui dispose aussi des interfaces d'utilisateurs (*API* ou *Application Programming Interface*) en R et Python ce qui a propulsé son utilisation massive dans la communauté mondiale de la Data Science. R et Python étant deux langages très populaires en Data Science. En gros **H2O**, de par sa rapidité et ses fonctionnalités évolutives, permet de créer des modèles d'apprentissage automatique en toute simplicité.

**Pourquoi H2O et qu'est-ce que H2O AutoML ?** Ces dernières années, la demande d'experts en Machine Learning a dépassé l'offre, malgré l'afflux de personnes entrant dans le domaine. De plus, il y a beaucoup de buzz pour les algorithmes de Machine Learning ainsi qu'une forte exigence pour ses experts non seulement en terme de compréhension mathématique mais aussi en terme de codage informatique. Pour combler cette lacune, de grands progrès ont été réalisés dans le développement de logiciels d'apprentissage automatique conviviaux pouvant être utilisés par des non-experts. L'Intelligence Artificielle n'a en réalité plus rien d'artificiel. Elle est déjà là, présente et concrète dans de nombreux domaines et elle présente de nombreux avantages Ceci étant, elle doit donc être accessible à tout le monde. La mission de **H20** est donc de démocratiser l'Intelligence Artificielle pour tous. **H2O** est subdivisée en deux produits pricipaux qui ont tous les deux le même objectif d'automatiser le flux de travail en Machine Learning, qui comprend la formation et le réglage automatiques de nombreux modèles dans un délai spécifié par l'utilisateur lui-même.

- ***H2O AutoML*** : cet outil, que nous verrons dans ce tutoriel, peut être utilisé par des utilisateurs avancés (pas forcément des experts). **H2O AutoML** fournit une fonction permet d'exécuter en seulement quelques lignes de code un grand nombre de tâches liées à la modélisation qui nécessiteraient généralement de nombreuses lignes de code. Cela permet de libérer du temps à l'utilisateur pour se concentrer sur d'autres aspects des étapes de la Data Science telles que le prétraitement des données, l'ingénierie des fonctionnalités (*Feature Engineering*) et le déploiement de modèles.

- ***H2O Flow*** : H20 Flow est en quelque sorte l'interface web graphique de H2O AutoML qui permet de créer et d'évaluer la performance des modèles de Machine ou de Deep Learning à partir de simples clics et sans écrire une seule ligne de code. Génial n'est-ce pas :)

Mais ATTENTION ! Bien que H2O permet aux non-experts d'expérimenter facilement l'apprentissage automatique, il reste encore beaucoup de connaissances et d'expérience en Data Science qui sont nécessaires pour produire des modèles de Machine Learning hautement performants. Les réseaux de neurones profonds en particulier, ce qu'on appelle Deep Learning restent quand même difficiles à régler correctement pour un non-expert.


Voci une petite vidéo de [SRI AMBATI](https://youtu.be/izd3jIzUvTA), CEO de **H2O.AI** qui parle de cette société innovante.

### <font color=red>POUR VITE MAITRISER LE MACHINE LEARNING AVEC PYTHON :

Si vous êtes un débutant en Data Science et que vous aimerez comprendre rapidement les bases fondamentales du Machine Learning sans rentrer dans les théories complexes qui vont vous fatiguer, je vous conseille le livre intitulé [Machine Learning par la pratique avec Python: Projets réels dans les Finances, l'Immobilier, le Trading, la Santé, le Marketing, etc.](https://www.amazon.fr/gp/product/B08DV8X9D2/ref=dbs_a_def_rwt_hsch_vamf_tkin_p1_i3). Ce livre est purement pratique car il vous permet d'apprendre à créer et à évaluer des modèles de Machine Learning en traitement des problématiques rencontrées en entreprises. Grâce à ce livre, vous puvez vous constituer votre propre portfolio de projets et vous faire remarquer par les recruteurs.

A travers ce livre, vous apprendrez à :

- Nettoyer un jeu de données et la rendre prête pour la modélisation (Traitement des valeurs manquantes, Détection et suppression des outliers, Encodage des variables catégorielles, Normalisation des données, etc.) ;

- Construire un modèle de classification (LogisticRegression, RandomForestClassifier, DecisionTreeClassifier, KNeighborsClassifier, etc.) et d'un modèle de régression (LinearRegression, RandomForestRegressor, DecisionTreeRegressor, KNeighborsRegressor, etc.) ;

- Evaluer la performance d’un modèle (Données d’entraînement et d’évaluation, Choix de la métrique, Validation croisée, Robustesse du modèle, etc.) ;

- effectuer des prédictions ;

- modéliser des séries temporelles et effectuer des prévisions ;

- rechercher les hyperparamètres optimaux d'un modèle en utilisant les méthodes Grid Search et Random Search ;

- automatiser la sélection du meilleur modèle avec l'outil TPOT ;ⱷautomatiser le flux de travail de vos projets de Machine Learning ;

- effectuer des segmentations avec des algorithmes comme KMeans ;

- réduire la dimension de grand ensembles de données en utilisant l'ACP, ...etc.

![couverture_jpeg.jpg](attachment:couverture_jpeg.jpg)

## <font color=green> Tâche 2 : Importation des librairies/fonctions nécessaires

Pour installer h2o et pouvoir l'utiliser avec Python, vous pouvez exécuter le code suivant :

***pip install -U h2o***

Pour d'éventuels problèmes d'installation, veuillez consulter la page : https://docs.h2o.ai/h2o/latest-stable/h2o-docs/downloading.html
"""

# Librairies nécessaires

import pandas as pd

import numpy as np

import matplotlib.pyplot as plt

import h2o

from h2o.automl import H2OAutoML

"""## <font color=green> Tâche 3 : Importation et Exploration des données

Les données utilisées dans ce cadre de ce projet proviennent de [UCI Machine Learning](https://archive.ics.uci.edu/ml/datasets/Bank+Marketing) qui est un célèbre répertoire de données pour s'entraîner dans les différentes tâches en Machine Learning (Classification, Régression, etc.). Il s'agit précisément des données liées à des campagnes de marketing direct d'une institution bancaire portugaise. Ici, il s'agit d'une tâche de classification binaire qui consiste à prédire si un client de la banque va oui ('yes') ou non ('no') souscrire à un dépôt bancaire à terme. Un dépôt à terme (DAT) est une somme bloquée sur un compte bancaire par un particulier ou une entreprise en contrepartie du versement d'intérêts. Une fois que le client a souscrit à un tel compte, son argent pourra être retiré qu'à l'échéance d'une certaine période définie préalablement lors de l'ouverture du compte bloqué. Ce type de dépôt est très profitable aux banques car il leur permet de disposer de beaucoup de liquidités et donc de pouvoir faire de bonnes affaires avec l'argent des épargnants.

![mufid-majnun-LVcjYwuHQlg-unsplash.jpg](attachment:mufid-majnun-LVcjYwuHQlg-unsplash.jpg)

Les données sont également disponibles directement sur ma page [GitHub](https://github.com/JosueAfouda/Machine-Learning-par-la-pratique-avec-Python/raw/master/bank-additional-full.csv).
"""

# Importation des données

file = 'https://github.com/JosueAfouda/Machine-Learning-par-la-pratique-avec-Python/raw/master/bank-additional-full.csv'

df = pd.read_csv(file, sep = ';')

df.head()

"""***y*** est la variable cible qui indique si le client a oui ('yes') ou non ('no') souscrit à un dépôt bancaire à terme."""

df.info()

"""La dataframe ne contient pas de valeurs manquantes.

## <font color=green> Tâche 4 : Préparation des données
"""

# Initialisation de h2o

h2o.init()

"""L'adresse url devant de H2O_connection_url vous permet d'ouvrir une session locale de h2o Flow sur votre ordinateur. Nous n'utiliserons pas h2o Flow dans ce tutoriel. H2O fera l'objet d'un autre tutiriel à retrouver toujours sur mon [site web](https://afouda-datascience.com/) ou sur ma [ma chaîne YouTube](https://www.youtube.com/channel/UCpd56FfjlkKbkHlbgY6XE3w)."""

# Transformation de la dataframe pandas df en un objet H2O frame

h2o_df = h2o.H2OFrame(df)

# Tout comme dans Pandas, vous pouvez voir le résumé statistique d'une dataframe H2O

h2o_df.describe()

# Variables indépendantes (Features) et Variable cible (Target)

train, test = h2o_df.split_frame(ratios = [0.75]) # 25% des observations pour le test set

x = train.columns

y = 'y'

x.remove(y)

"""## <font color=green> Tâche 5 : Exécution de H20 AutoML"""

# Table de fréquence de la variable cible

df.y.value_counts(normalize = True)

"""Nous constatons qu'il y a un déséquilibre de classe au niveau de la variable cible. Le déséquilibre de classe peut affacter négativement la performance d'un modèle de classification automatique. Il existe des méthodes plus ou moins complexes pour résoudre ce problème de déséquilibre de classe. Heureusement avec H2OAutoML, on peut résoudre facilement ce problème."""

# Commented out IPython magic to ensure Python compatibility.
# Création d'un modèle H2OAutoML

aml = H2OAutoML(max_runtime_secs = 600,
                balance_classes = True,
                stopping_metric = 'logloss',
                project_name ='Final',
                seed = 1)

# Entraînement du modèle

# %time aml.train(x = x, y = y, training_frame = train)

"""## <font color=green> Tâche 6 : Tableau de classement des modèles trouvés par AutoML"""

# Tableau de classement

lb = aml.leaderboard

lb.head(rows = lb.nrows) # Affichage de toutes les lignes

# Affichage d'autres colonnes du tableau de classement

lb = h2o.automl.get_leaderboard(aml, extra_columns = 'ALL')

lb

# Meilleur modèle

model = aml.leader

model

"""## <font color=green> Tâche 7 : Prédiction et Evaluation du meilleur modèle sur les données de test"""

# Performance du meilleur modèle sur les données de test

model.model_performance(test)

# Importance des prédicteurs

model.varimp_plot(num_of_features = len(x))

"""**ATTENTION** : Il est possible que vous ayez une erreur après exécution du code ci-dessus. En effet, certains algorithmes au niveau d'AutoML n'ont pas d'attribut donnant l'importance des prédicteurs."""

# Prédictions sur les données de test

preds = model.predict(test)

preds

"""![mon_logo.jpg](attachment:mon_logo.jpg)"""